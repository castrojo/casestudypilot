# CNCF Case Study Automation - Design

**Date:** February 9, 2026  
**Status:** Active

---

## Overview

Automate the creation of CNCF end-user case studies from KubeCon YouTube videos using GitHub Copilot Agentic Workflows and minimal Python tools.

**Goal:** GitHub issue with YouTube URL → Automated pull request with publication-ready case study

---

## Architecture

### High-Level Flow

```
GitHub Issue (YouTube URL)
         ↓
GitHub Copilot Agent
         ↓
    ┌────┴────────────────┐
    ↓                     ↓
Copilot Skills      Python Tools
(AI Processing)     (Data Fetching)
    ↓                     ↓
    └────┬────────────────┘
         ↓
   Pull Request
```

### Division of Responsibility

**GitHub Copilot Skills (.github/copilot-skills/):**
- Transcript correction (fix CNCF term capitalization, speech-to-text errors)
- Structure extraction (identify projects, metrics, sections)
- Content generation (write Background, Challenge, Solution, Impact sections)
- **Model selection** (Copilot chooses GPT-4, Claude, Gemini, etc.)

**Python Tools (casestudypilot/):**
- YouTube API client (fetch metadata, transcript)
- Company verifier (check CNCF Landscape membership)
- Markdown assembler (render Jinja2 template)
- Quality validator (basic checks)

---

## Components

### 1. GitHub Copilot Skills

#### Skill: transcript-correction.skill.md
**Purpose:** Fix speech-to-text errors in YouTube captions

**Input:** Raw transcript text

**Process:**
- Fix CNCF project capitalization (kubernetes → Kubernetes, argo cd → Argo CD)
- Correct common errors (cueectl → kubectl, micro services → microservices)
- Preserve code blocks, company names, URLs

**Output:** Corrected transcript

---

#### Skill: transcript-analysis.skill.md
**Purpose:** Extract structured information from transcript

**Input:** Corrected transcript

**Process:**
- Identify CNCF projects mentioned
- Extract quantitative metrics (percentages, time savings, scale)
- Classify content into sections (Background, Challenge, Solution, Impact)

**Output:** JSON with projects, metrics, section classifications

---

#### Skill: case-study-generation.skill.md
**Purpose:** Generate publication-ready case study content

**Input:** Analysis results, video metadata

**Process:**
- Generate Background section (company context, 2-3 paragraphs)
- Generate Challenge section (problems faced, 1-2 paragraphs + bullets)
- Generate Solution section (CNCF tech adopted, 2-3 paragraphs)
- Generate Impact section (results + metrics, 1-2 paragraphs + bullets)
- Follow CNCF style guidelines

**Output:** Markdown sections

---

### 2. Python Tools

#### youtube_client.py (~100 lines)
**Purpose:** Fetch video data from YouTube

**Implementation:**
```python
class YouTubeClient:
    def get_video_data(self, video_id: str) -> dict:
        """
        Fetch metadata and transcript.
        
        Returns:
            {
                "video_id": "...",
                "title": "...",
                "speakers": ["..."],
                "company": "...",
                "transcript": "...",
                "published_at": "...",
                "duration_seconds": 600
            }
        """
        # Use YouTube Data API v3 for metadata
        # Use youtube-transcript-api for captions (no quota)
        # Parse speakers/company from title or description
```

**Dependencies:**
- `google-api-python-client` (YouTube Data API)
- `youtube-transcript-api` (caption fetching)

---

#### company_verifier.py (~80 lines)
**Purpose:** Verify company is CNCF end-user member

**Implementation:**
```python
class CompanyVerifier:
    def verify(self, company_name: str) -> dict:
        """
        Check CNCF Landscape membership with fuzzy matching.
        
        Returns:
            {
                "is_member": True,
                "matched_name": "Intuit",
                "confidence": 0.98
            }
        """
        # Fetch CNCF Landscape YAML
        # Parse end-user companies
        # Fuzzy match with rapidfuzz (90% threshold)
```

**Dependencies:**
- `rapidfuzz` (fuzzy string matching)
- `httpx` (HTTP client)
- `pyyaml` (YAML parsing)

---

#### assembler.py (~50 lines)
**Purpose:** Render final case study markdown

**Implementation:**
```python
class CaseStudyAssembler:
    def assemble(
        self,
        company: str,
        sections: dict,
        projects: list,
        video_url: str,
        speakers: list
    ) -> str:
        """Render Jinja2 template with data."""
        # Load case_study.md.j2 template
        # Insert sections, metadata
        # Return complete markdown
```

**Dependencies:**
- `jinja2` (template rendering)

---

#### validator.py (~50 lines)
**Purpose:** Basic quality checks

**Implementation:**
```python
class QualityValidator:
    def validate(self, markdown: str, analysis: dict) -> dict:
        """
        Simple quality checks.
        
        Returns:
            {
                "quality_score": 0.85,
                "issues": ["warning: short section"]
            }
        """
        # Check all sections present
        # Check word counts (minimum 50 words per section)
        # Check projects mentioned (minimum 2)
        # Check metrics present (minimum 1)
```

---

### 3. GitHub Agentic Workflow

#### .github/agentic-workflows/process-case-study.yml

**Trigger:** GitHub issue labeled `case-study` with YouTube URL in body

**Steps:**

1. **Parse video URL** (GitHub Action script)
   - Extract video ID from issue body

2. **Fetch video data** (Python tool)
   - Run: `python -m casestudypilot.youtube_client --video-id <id>`
   - Output: `video_data.json`

3. **Verify company** (Python tool)
   - Run: `python -m casestudypilot.company_verifier --company <name>`
   - Exit if not CNCF member

4. **Correct transcript** (Copilot skill)
   - Skill: `transcript-correction`
   - Input: Raw transcript
   - Output: `corrected_transcript.txt`

5. **Analyze transcript** (Copilot skill)
   - Skill: `transcript-analysis`
   - Input: Corrected transcript
   - Output: `analysis.json`

6. **Generate case study** (Copilot skill)
   - Skill: `case-study-generation`
   - Input: Analysis + metadata
   - Output: `sections.json`

7. **Assemble markdown** (Python tool)
   - Run: `python -m casestudypilot.assembler`
   - Output: `case-studies/<company>.md`

8. **Validate quality** (Python tool)
   - Run: `python -m casestudypilot.validator`
   - Warn if score < 0.6

9. **Create pull request** (GitHub Action)
   - Branch: `case-study-<company>`
   - Include quality score and metadata in PR body

---

## File Structure

```
casestudypilot/
├── .github/
│   ├── agentic-workflows/
│   │   └── process-case-study.yml
│   └── copilot-skills/
│       ├── transcript-correction.skill.md
│       ├── transcript-analysis.skill.md
│       └── case-study-generation.skill.md
│
├── casestudypilot/
│   ├── youtube_client.py
│   ├── company_verifier.py
│   ├── assembler.py
│   └── validator.py
│
├── templates/
│   └── case_study.md.j2
│
├── tests/
│   └── test_integration.py
│
├── requirements.txt
└── README.md
```

**Total Python code:** ~300 lines

---

## Dependencies

```txt
# requirements.txt

# YouTube
google-api-python-client==2.117.0
youtube-transcript-api==0.6.2

# Company verification
rapidfuzz==3.6.1
pyyaml==6.0.1
httpx==0.26.0

# Templates
jinja2==3.1.3

# Data models
pydantic==2.6.1
```

**No AI SDKs required** - Copilot manages model selection

---

## Case Study Template

```jinja2
<!-- templates/case_study.md.j2 -->
---
title: {{ company }} Case Study
linkTitle: {{ company }}
case_study_styles: true
cid: caseStudies
---

## About {{ company }}

{{ background }}

## Challenge

{{ challenge }}

## Solution

{{ solution }}

## Impact

{{ impact }}

## Projects Used

{% for project in projects %}
- **{{ project }}**
{% endfor %}

---

**Video:** [Watch the talk]({{ video_url }})  
**Speakers:** {{ speakers }}  
**Date:** {{ date }}
```

---

## Testing Strategy

### Integration Tests (15 tests)

Focus on end-to-end behavior, not unit testing internal logic.

**Key test cases:**
1. YouTube client fetches Intuit video correctly
2. Company verifier finds "Intuit" in Landscape (exact match)
3. Company verifier finds "Intuit Inc" in Landscape (fuzzy match)
4. Assembler renders complete markdown with all sections
5. Validator detects missing sections
6. Validator detects short sections (<50 words)
7. Full pipeline generates valid case study from known video

**Test fixtures:**
- Sample transcript from Intuit video
- Mock CNCF Landscape YAML with test companies
- Expected output markdown (golden file)

---

## Implementation Timeline

### Week 1: Python Tools (5 days)
- Day 1-2: Project setup, models, YouTube client
- Day 3: Company verifier
- Day 4-5: Assembler, validator, tests

**Milestone:** All Python tools working, tested

---

### Week 2: Copilot Skills (5 days)
- Day 6-7: Transcript correction + analysis skills
- Day 8-9: Case study generation skill
- Day 10: Agentic workflow integration

**Milestone:** All Copilot skills defined, workflow functional

---

### Week 3: Integration & Polish (2-5 days)
- Day 11-12: End-to-end testing with real videos
- Day 13-14: Documentation, error handling
- Day 15: Buffer for issues

**Milestone:** Production ready

---

## Quality Criteria

**Functional Requirements:**
- ✅ Process GitHub issue with YouTube URL
- ✅ Verify company is CNCF member
- ✅ Generate case study in CNCF style
- ✅ Create pull request automatically

**Quality Requirements:**
- ✅ Quality score ≥ 0.60
- ✅ All 4 sections present (Background, Challenge, Solution, Impact)
- ✅ Minimum 2 CNCF projects mentioned
- ✅ Minimum 1 quantitative metric included

**Performance Requirements:**
- ✅ End-to-end pipeline: < 2 minutes
- ✅ Python tools: < 5 seconds each

---

## Design Principles

### 1. Simplicity First
- Minimal Python code (only data fetching/assembly)
- No custom NLP pipelines
- No hardcoded AI model selection
- Simple regex-based parsing where sufficient

### 2. Leverage Copilot
- Let Copilot handle all AI tasks
- Copilot chooses best model for each task
- Skills are easy to update (just edit markdown)

### 3. Separation of Concerns
- Python: Data operations
- Copilot: AI operations
- GitHub Actions: Orchestration

### 4. Maintainability
- Small, focused files (~50-100 lines each)
- Clear interfaces between components
- Integration tests > unit tests
- Documentation with examples

---

## Future Enhancements

**Phase 2 (after MVP):**
- Batch processing (multiple videos at once)
- Quality improvements based on feedback
- Support for podcast transcripts

**Phase 3 (long-term):**
- Auto-merge high-quality case studies
- Analytics on projects/companies mentioned
- Notifications (Slack/Discord)

---

## Example Copilot Skill

```markdown
<!-- .github/copilot-skills/transcript-correction.skill.md -->

# Transcript Correction

## Purpose
Fix speech-to-text errors in CNCF talk transcripts.

## Input
Raw transcript from YouTube captions.

## Instructions

Correct the transcript following these rules:

1. **Fix CNCF Project Capitalization:**
   - kubernetes → Kubernetes
   - prometheus → Prometheus  
   - argo cd → Argo CD
   - helm → Helm
   - istio → Istio

2. **Fix Common Errors:**
   - cueectl → kubectl
   - micro services → microservices
   - git ops → GitOps

3. **Preserve:**
   - Code blocks: `kubectl get pods`
   - Company names
   - URLs
   - Acronyms

4. **Keep Original Phrasing:**
   - Do NOT rephrase sentences
   - Only fix obvious errors

## Output
Return only the corrected transcript as plain text.

## Example

Input:
```
We use kubernetes and argo cd for deployments.
Run `kubectl get pods` to check status.
```

Output:
```
We use Kubernetes and Argo CD for deployments.
Run `kubectl get pods` to check status.
```
```

---

## Success Metrics

**Development:**
- ✅ Complete in 12-15 days
- ✅ Total code < 1,000 lines
- ✅ All integration tests passing

**Operation:**
- ✅ Generate 10+ case studies per month
- ✅ Quality score average ≥ 0.70
- ✅ 90% of PRs require only minor edits

---

**End of Design Document**
